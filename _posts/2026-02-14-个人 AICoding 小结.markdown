---
layout: post
title:  "个人 AICoding 小结"
date:   2026-02-14 23:32:53 +0800
categories: jekyll update
---

前段时间 Anthropic 的研发团队发布了一篇非常有意思的文章 [How AI assistance impacts the formation of coding skills](https://www.anthropic.com/research/AI-assistance-coding-skills) ,主要解释了一个问题:**AI 写代码能让你更快交付，但会不会让你“学得更慢、会得更少”？**

结论是：**如果只是把 AI 当作“代写器”，确实会降低理解与掌握。但如果把它当作“解释器+校对员+对拍伙伴”，则能事半功倍。**

# 不要把思考过程完全交给 AI

AI 很容易让我们产生“认知卸载”（Cognitive Offloading）的依赖。一旦习惯了只输入需求、复制粘贴代码，我们的大脑就会停止对代码逻辑、边界条件和系统设计的深度思考。

**建议的做法：**
- **先思考，后提示（Think Before Prompting）**：在向 AI 提问前，先在脑海中或纸上画出大致的逻辑结构。不要让 AI 帮你“设计”一切，而是让它帮你“实现”你的设计。
- **保持 Reviewer 的心态**：把 AI 当作一个刚入职的初级工程师。它提交的代码（Pull Request），你必须逐行阅读、理解，并问自己：“如果有 Bug，会在哪里？”、“这里的内存管理安全吗？”。
- **主动式学习**：不要只问“怎么做”，要多问“为什么”。比如：“为什么要用这个库？”、“有没有更好的替代方案？”、“这段代码在并发场景下安全吗？”。

# 好好写一份 AGENTS.md

AI 的上下文窗口（Context Window）虽然越来越大，但它依然需要明确的“游戏规则”才能表现得最好。与其每次都重复你的偏好，不如把项目规范固化下来。

**AGENTS.md 的作用：**
- **统一编码规范**：明确项目的代码风格（如命名约定、目录结构、使用的库版本）。
- **定义“角色”与“原则”**：告诉 AI 它应该扮演什么角色（如“资深架构师”），以及它必须遵守的原则（如“优先使用组合而非继承”、“所有公共方法必须有文档”）。
- **沉淀最佳实践**：把项目中容易踩的坑、特殊的业务逻辑记录在案，让 AI 在生成代码时能参考，避免重蹈覆辙。
- **双份配置模式**：可以维护一份通用的 `AGENTS.md` 和一份针对特定 AI 工具的配置（如 `CLAUDE.md`），确保不同工具都能理解你的要求。

# 当心 AI 一本正经的胡说八道

AI 模型（尤其是 LLM）本质上是基于概率的预测机，它们很容易产生“幻觉”（Hallucination），即自信满满地胡说八道。

**防范策略：**
- **交叉验证**：对于 AI 提供的 API 用法或生僻的库，务必去官方文档或源码中核实。不要盲目相信。
- **要求解释与来源**：让 AI 解释它的代码逻辑，并要求它提供参考来源。如果它无法解释清楚，或者来源不存在，那很可能是幻觉。
- **关注“调试”与“概念理解”**：Anthropic 的研究发现，AI 辅助下，调试能力和概念理解能力最容易下降。因此，在这两方面要格外警惕，不要让 AI 剥夺了你排查问题的机会。

## 让 AI 去 review AI

一个人（或一个模型）很容易陷入思维定势。利用 AI 的多角色扮演能力，可以让它自己查漏补缺。

**具体操作：**
- **反向提问（Reverse Questioning）**：让 AI 反问你需求中的漏洞、缺失的异常路径、性能瓶颈。
- **角色切换**：让 AI 生成代码后，再开启一个新的会话（或让它切换角色），扮演“苛刻的代码审查员”，对刚才生成的代码进行 Review。
- **“苏格拉底式”教学**：让 AI 出题考你，或者让你解释某段代码，然后它来纠正你的理解偏差。

## 使用 rust 这种强编译语言

- **Rust 确实“强势”**：借用检查、类型系统、生命周期、 Result / Option 让很多潜在错误在编译期暴露。
- **这对 AI 生成代码很友好**：编译器能当“高质量的静态审查器”，快速告诉你哪里违反了安全或类型规则。AI 生成的代码往往能跑通逻辑，但容易忽略内存安全或并发安全，Rust 的编译器正好能卡住这些问题。
- **减少“调试差距”**：既然 AI 容易导致调试能力下降，那么使用一门“编译通过即大概率正确”的语言，可以减少运行时莫名其妙崩溃的概率，强迫你在编写阶段就理清逻辑。
- **迭代模式**：AI 生成 -> 编译器报错 -> 把错误喂给 AI -> AI 修正。这个循环比“运行 -> 崩溃 -> 猜测 -> 调试”要高效且安全得多。
